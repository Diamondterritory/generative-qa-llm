{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d150c147-2211-4326-9b1c-014bd3ee222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2Model, GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b9655f-e589-49bf-985c-5bb5624f96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(dataset, mode):\n",
    "  dict_mode=dataset[mode]\n",
    "  option=dict_mode['options']\n",
    "  answer=dict_mode['answer']\n",
    "  article=dict_mode['article']\n",
    "  question=dict_mode['question']\n",
    "\n",
    "  return option, answer, article, question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76355844-b8b4-4a23-b5ac-bc59c7e5ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_engineering(answer, options):\n",
    "  complete_answer=[]\n",
    "  option_index = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}\n",
    "  for i in range(len(answer)):\n",
    "    option_number=answer[i]\n",
    "    complete_answer.append(options[i][option_index[option_number]])\n",
    "  print(f'Total length of the dataset: {len(complete_answer)}')\n",
    "  return complete_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc0d17e-df6d-4b77-a9ca-4cfbed0aea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_generation(article, question):\n",
    "  complete_prompt=[\n",
    "      'Answer the following question based on the passage - \\n'\n",
    "      + art + '\\n'\n",
    "      + 'Question: '+ ques + '\\n'\n",
    "      + 'Answer: '\n",
    "      for art,ques in zip(article,question) \n",
    "  ]\n",
    "  return complete_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b792d1-b14d-422e-b6b7-7c027682ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/harsh/.cache/huggingface/datasets/ehovy___parquet/all-53c1c61cb0110145/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aef04c799324882b312d8e1fc617ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the dataset: 175732\n",
      "Total length of the dataset: 9868\n",
      "Total length of the dataset: 9774\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "dataset = load_dataset(\"ehovy/race\", 'all', ignore_verifications=True)\n",
    "\n",
    "# Extracting the dataset specifics\n",
    "train_options, train_answer, train_article, train_question = extract_data(dataset, 'train')\n",
    "test_options, test_answer, test_article, test_question = extract_data(dataset, 'test')\n",
    "validation_options, validation_answer, validation_article, validation_question = extract_data(dataset, 'validation')\n",
    "\n",
    "# Getting the correct answers\n",
    "train_correct_answer = answer_engineering(train_answer, train_options)\n",
    "test_correct_answer = answer_engineering(test_answer, test_options)\n",
    "validation_correct_answer = answer_engineering(validation_answer, validation_options)\n",
    "\n",
    "# Creating the prompts\n",
    "train_prompt = prompt_generation(train_article, train_question)\n",
    "test_prompt = prompt_generation(test_article, test_question)\n",
    "validation_prompt = prompt_generation(validation_article, validation_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76577c08-d352-41b7-879e-f5393880310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efadb82e-fbb6-42c4-b2ab-ddc367f2bb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the following question based on the passage - \\nLast week I talked with some of my students about what they wanted to do after they graduated, and what kind of job prospects  they thought they had.\\nGiven that I teach students who are training to be doctors, I was surprised do find that most thought that they would not be able to get the jobs they wanted without \"outside help\". \"What kind of help is that?\" I asked, expecting them to tell me that they would need a   or family friend to help them out.\\n\"Surgery ,\" one replied.\\nI was pretty alarmed by that response. It seems that the graduates of today are increasingly willing to go under the knife to get ahead of others when it comes to getting a job .\\nOne girl told me that she was considering surgery to increase her height. \"They break your legs, put in special extending screws, and slowly expand the gap between the two ends of the bone as it re-grows, you can get at least 5 cm taller!\"\\nAt that point, I was shocked. I am short, I can\\'t deny that, but I don\\'t think I would put myself through months of agony just to be a few centimetres taller. I don\\'t even bother to wear shoes with thick soles, as I\\'m not trying to hide the fact that I am just not tall!\\nIt seems to me that there is a trend towards wanting \"perfection\" , and that is an ideal that just does not exist in reality.\\nNo one is born perfect, yet magazines, TV shows and movies present images of thin, tall, beautiful people as being the norm. Advertisements for slimming aids, beauty treatments and cosmetic surgery clinics fill the pages of newspapers, further creating an idea that \"perfection\" is a requirement, and that it must be purchased, no matter what the cost. In my opinion, skills, rather than appearance, should determine how successful a person is in his/her chosen career.\\nQuestion: We can know from the passage that the author works as a_.\\nAnswer: '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fbb78eb-51a0-44cc-a23c-8150039e358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vicgalle/gpt2-alpaca-gpt4'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, device=device) # need to change tokenizer based off model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13658b80-9614-48cd-8614-2a2c63c198bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = train_prompt[0]\n",
    "y_hat = train_correct_answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07176f83-ebc8-4cd2-8cb3-2c7b41f70fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(sequence, return_tensors='pt').to(device)\n",
    "outputs = model.generate(inputs, max_length=len(inputs[0]) + 10, do_sample=True, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "y_pred = text.split('\\nAnswer:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "472c65e2-a32f-4ee1-9094-ec2a8003c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: teacher\n",
      "Generated:   The author is not a doctor. He/She\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct: {y_hat}\\nGenerated: {y_pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
