{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d150c147-2211-4326-9b1c-014bd3ee222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2Model, GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b9655f-e589-49bf-985c-5bb5624f96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(dataset, mode):\n",
    "  dict_mode=dataset[mode]\n",
    "  option=dict_mode['options']\n",
    "  answer=dict_mode['answer']\n",
    "  article=dict_mode['article']\n",
    "  question=dict_mode['question']\n",
    "\n",
    "  return option, answer, article, question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76355844-b8b4-4a23-b5ac-bc59c7e5ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_engineering(answer, options):\n",
    "  complete_answer=[]\n",
    "  option_index = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}\n",
    "  for i in range(len(answer)):\n",
    "    option_number=answer[i]\n",
    "    complete_answer.append(options[i][option_index[option_number]])\n",
    "  print(f'Total length of the dataset: {len(complete_answer)}')\n",
    "  return complete_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc0d17e-df6d-4b77-a9ca-4cfbed0aea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_generation(article, question):\n",
    "  complete_prompt=[\n",
    "      'Answer the following question based on the passage - \\n'\n",
    "      + art + '\\n'\n",
    "      + 'Question: '+ ques + '\\n'\n",
    "      + 'Answer: '\n",
    "      for art,ques in zip(article,question) \n",
    "  ]\n",
    "  return complete_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71678d0-75aa-4456-b6d3-40b59144fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_hat(qn, ans):\n",
    "    if '_' in qn:\n",
    "            return qn.replace('_', ' ' + ans) # original dataset does not have spaces before the '_'\n",
    "    return ans\n",
    "\n",
    "def y_hat_generation(questions, answers):\n",
    "    return [get_y_hat(qn, answers[idx]) for idx, qn in enumerate(questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b792d1-b14d-422e-b6b7-7c027682ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/miniconda3/envs/deep-learning/lib/python3.11/site-packages/datasets/load.py:1748: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n",
      "Found cached dataset parquet (/home/harsh/.cache/huggingface/datasets/ehovy___parquet/all-53c1c61cb0110145/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842f820287f84dcaae87fee7883d0c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "dataset = load_dataset(\"ehovy/race\", 'all', ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1867c571-f35d-4688-ac50-04fbc46fc8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the dataset: 175732\n",
      "Total length of the dataset: 9868\n",
      "Total length of the dataset: 9774\n"
     ]
    }
   ],
   "source": [
    "# Extracting the dataset specifics\n",
    "train_options, train_answer, train_article, train_question = extract_data(dataset, 'train')\n",
    "test_options, test_answer, test_article, test_question = extract_data(dataset, 'test')\n",
    "validation_options, validation_answer, validation_article, validation_question = extract_data(dataset, 'validation')\n",
    "\n",
    "# Getting the correct answers\n",
    "train_correct_answer = answer_engineering(train_answer, train_options)\n",
    "test_correct_answer = answer_engineering(test_answer, test_options)\n",
    "validation_correct_answer = answer_engineering(validation_answer, validation_options)\n",
    "\n",
    "# Creating the prompts\n",
    "train_prompt = prompt_generation(train_article, train_question)\n",
    "test_prompt = prompt_generation(test_article, test_question)\n",
    "validation_prompt = prompt_generation(validation_article, validation_question)\n",
    "\n",
    "# Creating the y_hats\n",
    "train_y_hat = y_hat_generation(train_question, train_correct_answer)\n",
    "test_y_hat = y_hat_generation(test_question, test_correct_answer)\n",
    "validation_y_hat = y_hat_generation(validation_question, validation_correct_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76577c08-d352-41b7-879e-f5393880310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fbb78eb-51a0-44cc-a23c-8150039e358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vicgalle/gpt2-alpaca-gpt4'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, device=device) # need to change tokenizer based off model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13658b80-9614-48cd-8614-2a2c63c198bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 1\n",
    "sequence = train_prompt[ex]\n",
    "question = train_question[ex]\n",
    "y_hat = train_y_hat[ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07176f83-ebc8-4cd2-8cb3-2c7b41f70fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(sequence, return_tensors='pt').to(device)\n",
    "outputs = model.generate(inputs, max_length=len(inputs[0]) + 50, do_sample=True, num_beams=2, no_repeat_ngram_size=2, early_stopping=True)\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "y_pred = text.split('\\nAnswer:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472c65e2-a32f-4ee1-9094-ec2a8003c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Many graduates today turn to cosmetic surgery to_.\n",
      "Correct: Many graduates today turn to cosmetic surgery to get an advantage over others in job-hunting.\n",
      "Generated:   It is not uncommon for graduates to choose to undergo cosmetic surgeries, often with the help of a family member. Some people may also opt for surgery on their own, without the knowledge or consent of their parents or guardians. The choice is up to the\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {question}\\nCorrect: {y_hat}\\nGenerated: {y_pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
